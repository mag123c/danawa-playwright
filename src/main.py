from src.infra.danawa_scraper import DanawaScraper
from src.storage.file_storage import save_as_json

categories = [
    {
        "group_code": "13",
        "cate_name": "ì•„ì´ìŠ¤ë°•ìŠ¤",
        "cate_code": "42018",
        "ref_cate_code": "13342018",
        "depth": "3",
    },
    {
        "group_code": "13",
        "cate_name": "ì¿¨ëŸ¬ë°±",
        "cate_code": "42019",
        "ref_cate_code": "13342019",
        "depth": "3",
    },
    {
        "group_code": "14",
        "cate_name": "ì°¨ëŸ‰ìš©ëƒ‰ì˜¨ëƒ‰ì¥ê³ ",
        "cate_code": "36799",
        "ref_cate_code": "14236799",
        "depth": "3",
    },
]

for category in categories:
    print(f"ğŸ“¦ {category['cate_name']} ìˆ˜ì§‘ ì‹œì‘")
    scraper = DanawaScraper(
        group_code=category["group_code"],
        category_code=category["cate_code"],
        referer_code=category["ref_cate_code"],
        sub_category=category["cate_name"],
        depth=category["depth"]
    )
    items = scraper.scrape()
    save_as_json(items, category["cate_name"])
